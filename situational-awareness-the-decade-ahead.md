# Situational Awareness - The Decade Ahead

Author: Leopold Ashenbrenner
Link: [situationalawareness.pdf](https://situational-awareness.ai/wp-content/uploads/2024/06/situationalawareness.pdf)

To be fair, I think that Ray Kurzweil had a lot of the same ideas - ie. we would create AGI first and then it would bootstrap itself to ASI and at the point we reach ASI this is what Ray called the "Singularity"

It is absolutely insane when you consider how far AI has come since 2019. I remember using GPT-2 and it was weird and a toy. Now we have GPT-4 and entire businesses (including the one that employes me) are possible because of it.

When we look back at what GPT-2 could do and then we compare it to GPT-4, it's quite a stark jump in capability. Some are saying we won't see that jump again because we haven't gotten a new SOTA model since GPT-4 which finished training in 2022. But Leopold is saying that we will of course continue to make these exponential leaps in compute, algorithmic and "unhobbling" progress and could have a PhD level AI by 2027.

This manifesto really puts the progress in perspective. It's so hard to see how far you've come when you're still enamored with the fact that you're moving at mach 10.

I don't get how Leopold's paper is "terrifying"

He's basically saying that the people who are explicitly trying to develop AGI are going to succeed relatively soon

Which is the point of the whole thing isn't it? https://x.com/DannyMcAteer8/status/1801791141001449486
